{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script tries to use Word2Vec technique on Handelingen data\n",
    "For Dialects of Discord on the party level\n",
    "Milan van Lange, June 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Le chargement a nécessité le package : NLP\n",
      "\n",
      "Le chargement a nécessité le package : qdapDictionaries\n",
      "\n",
      "Le chargement a nécessité le package : qdapRegex\n",
      "\n",
      "Le chargement a nécessité le package : qdapTools\n",
      "\n",
      "Le chargement a nécessité le package : RColorBrewer\n",
      "\n",
      "\n",
      "Attachement du package : ‘qdap’\n",
      "\n",
      "\n",
      "Les objets suivants sont masqués depuis ‘package:tm’:\n",
      "\n",
      "    as.DocumentTermMatrix, as.TermDocumentMatrix\n",
      "\n",
      "\n",
      "L'objet suivant est masqué depuis ‘package:NLP’:\n",
      "\n",
      "    ngrams\n",
      "\n",
      "\n",
      "Les objets suivants sont masqués depuis ‘package:base’:\n",
      "\n",
      "    Filter, proportions\n",
      "\n",
      "\n",
      "\n",
      "Attachement du package : ‘dplyr’\n",
      "\n",
      "\n",
      "L'objet suivant est masqué depuis ‘package:qdapTools’:\n",
      "\n",
      "    id\n",
      "\n",
      "\n",
      "L'objet suivant est masqué depuis ‘package:qdapRegex’:\n",
      "\n",
      "    explain\n",
      "\n",
      "\n",
      "Les objets suivants sont masqués depuis ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "Les objets suivants sont masqués depuis ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(magrittr)\n",
    "library(tm)\n",
    "library(word2vec)\n",
    "library(XML)\n",
    "library(qdap)\n",
    "library(stringr)\n",
    "library(dplyr)\n",
    "library(lumberjack)\n",
    "library(readtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original xml files from local folder -------------------------------------\n",
    "# create empty value 'data' \n",
    "data <- NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set wd with xmls\n",
    "setwd(\"E:/Data PM 1940-90/1970\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract all .xml-filenames from folder/working directory\n",
    "files <- list.files(pattern=\".xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load texts into R\n",
    "for (filename in files) {\n",
    "  doc = xmlTreeParse(filename, useInternalNodes=TRUE)\n",
    "  top = xmlRoot(doc)\n",
    "  # get speech-node set\n",
    "  getNodeSet(doc, \"//*[local-name()='speech']\") -> proc\n",
    "  # extract names of speakers\n",
    "  xmlSApply(proc, xmlGetAttr, \"pm:speaker\", xmlValue) -> spreker\n",
    "  # extract unique identifier of every speech\n",
    "  xmlSApply(proc, xmlGetAttr, \"pm:id\", xmlValue) -> id\n",
    "  # extract speeches\n",
    "  xmlSApply(proc, xmlValue, \"//p\")-> sprkbrt\n",
    "  # extract names of parties\n",
    "  xmlSApply(proc, xmlGetAttr, \"pm:party\", NA) -> partij\n",
    "  partij <- as.character(partij)\n",
    "  na.pass(partij)\n",
    "  # create dataframe/overview of extracted values. \n",
    "  # bind values into dataframe\n",
    "  d2 <- data.frame(id, spreker, sprkbrt, partij)\n",
    "  rbind(data, d2) -> data\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start_log(data, logger = simple$new(), label = NULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "data$sprkbrt <- tolower(data$sprkbrt)\n",
    "data$sprkbrt <- removeWords(data$sprkbrt, stopwords(\"dutch\"))\n",
    "data$sprkbrt <- removePunctuation(data$sprkbrt, preserve_intra_word_dashes = TRUE)\n",
    "data$sprkbrt <- str_squish(data$sprkbrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We performed some pre-processing steps to the parliamentary data sets to remove noise and improve the quality of our WEMs. These steps include the lowercasing of all the words in the texts and the removal of interpunction, white spaces and general Dutch stop words. To perform these pre-processing steps, we used the R package tm, which also includes a standard list of stop words for Dutch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  use a copy of this when calculating values of spec. speaker or party\n",
    "dt <- data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create party and year specific datasets ---------------------------------\n",
    "# set wd\n",
    "path =\"\"\n",
    "setwd(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPN\n",
    "dt %>%\n",
    "  dplyr::filter(partij == \"CPN\") -> cpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpn %>%\n",
    "  dplyr::filter(str_detect(id, \"19691970\")) -> cpn.19691970\n",
    "cpn %>%\n",
    "  dplyr::filter(str_detect(id, \"19701971\")) -> cpn.19701971\n",
    "cpn %>%\n",
    "  dplyr::filter(str_detect(id, \"19711972\")) -> cpn.19711972\n",
    "cpn %>%\n",
    "  dplyr::filter(str_detect(id, \"19721973\")) -> cpn.19721973\n",
    "cpn %>%\n",
    "  dplyr::filter(str_detect(id, \"19731974\")) -> cpn.19731974\n",
    "cpn %>%\n",
    "  dplyr::filter(str_detect(id, \"19741975\")) -> cpn.19741975"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write file to use as training text \n",
    "write(cpn.19691970$sprkbrt, \"corpus19691970cpn.txt\")\n",
    "write(cpn.19701971$sprkbrt, \"corpus19701971cpn.txt\")\n",
    "write(cpn.19711972$sprkbrt, \"corpus19711972cpn.txt\")\n",
    "write(cpn.19721973$sprkbrt, \"corpus19721973cpn.txt\")\n",
    "write(cpn.19731974$sprkbrt, \"corpus19731974cpn.txt\")\n",
    "write(cpn.19741975$sprkbrt, \"corpus19741975cpn.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt %>%\n",
    "  dplyr::filter(partij == \"VVD\") -> vvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vvd %>%\n",
    "  dplyr::filter(str_detect(id, \"19691970\")) -> vvd.19691970\n",
    "vvd %>%\n",
    "  dplyr::filter(str_detect(id, \"19701971\")) -> vvd.19701971\n",
    "vvd %>%\n",
    "  dplyr::filter(str_detect(id, \"19711972\")) -> vvd.19711972\n",
    "vvd %>%\n",
    "  dplyr::filter(str_detect(id, \"19721973\")) -> vvd.19721973\n",
    "vvd %>%\n",
    "  dplyr::filter(str_detect(id, \"19731974\")) -> vvd.19731974\n",
    "vvd %>%\n",
    "  dplyr::filter(str_detect(id, \"19741975\")) -> vvd.19741975"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write file to use as training text \n",
    "write(vvd.19691970$sprkbrt, \"corpus19691970vvd.txt\")\n",
    "write(vvd.19701971$sprkbrt, \"corpus19701971vvd.txt\")\n",
    "write(vvd.19711972$sprkbrt, \"corpus19711972vvd.txt\")\n",
    "write(vvd.19721973$sprkbrt, \"corpus19721973vvd.txt\")\n",
    "write(vvd.19731974$sprkbrt, \"corpus19731974vvd.txt\")\n",
    "write(vvd.19741975$sprkbrt, \"corpus19741975vvd.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PVDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt %>%\n",
    "   dplyr::filter(partij == \"PvdA\") -> pvda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvda %>%\n",
    "   dplyr::filter(str_detect(id, \"19691970\")) -> pvda.19691970\n",
    "pvda %>%\n",
    "   dplyr::filter(str_detect(id, \"19701971\")) -> pvda.19701971\n",
    "pvda %>%\n",
    "   dplyr::filter(str_detect(id, \"19711972\")) -> pvda.19711972\n",
    "pvda %>%\n",
    "   dplyr::filter(str_detect(id, \"19721973\")) -> pvda.19721973\n",
    "pvda %>%\n",
    "   dplyr::filter(str_detect(id, \"19731974\")) -> pvda.19731974\n",
    "pvda %>%\n",
    "   dplyr::filter(str_detect(id, \"19741975\")) -> pvda.19741975"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write file to use as training text \n",
    "write(pvda.19691970$sprkbrt, \"corpus19691970pvda.txt\")\n",
    "write(pvda.19701971$sprkbrt, \"corpus19701971pvda.txt\")\n",
    "write(pvda.19711972$sprkbrt, \"corpus19711972pvda.txt\")\n",
    "write(pvda.19721973$sprkbrt, \"corpus19721973pvda.txt\")\n",
    "write(pvda.19731974$sprkbrt, \"corpus19731974pvda.txt\")\n",
    "write(pvda.19741975$sprkbrt, \"corpus19741975pvda.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt %>%\n",
    "   dplyr::filter(partij == \"CDA\") -> cda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cda %>%\n",
    "   dplyr::filter(str_detect(id, \"19691970\")) -> cda.19691970\n",
    "cda %>%\n",
    "   dplyr::filter(str_detect(id, \"19701971\")) -> cda.19701971\n",
    "cda %>%\n",
    "   dplyr::filter(str_detect(id, \"19711972\")) -> cda.19711972\n",
    "cda %>%\n",
    "   dplyr::filter(str_detect(id, \"19721973\")) -> cda.19721973\n",
    "cda %>%\n",
    "   dplyr::filter(str_detect(id, \"19731974\")) -> cda.19731974\n",
    "cda %>%\n",
    "   dplyr::filter(str_detect(id, \"19741975\")) -> cda.19741975"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write file to use as training text \n",
    "write(cda.19691970$sprkbrt, \"corpus19691970cda.txt\")\n",
    "write(cda.19701971$sprkbrt, \"corpus19701971cda.txt\")\n",
    "write(cda.19711972$sprkbrt, \"corpus19711972cda.txt\")\n",
    "write(cda.19721973$sprkbrt, \"corpus19721973cda.txt\")\n",
    "write(cda.19731974$sprkbrt, \"corpus19731974cda.txt\")\n",
    "write(cda.19741975$sprkbrt, \"corpus19741975cda.txt\")\n",
    "#etc for all other years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setwd(\"Q:/Onderzoeksdata_Milan/Surfdrive_milan/Shared/Dialects_of_Discord/Raw_data/Plain_texts_timeslot/1970-1975\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# All parties\n",
    "dt %>%\n",
    "  dplyr::filter(str_detect(id, \"19691970\")) -> dt.19691970\n",
    "dt %>%\n",
    "  dplyr::filter(str_detect(id, \"19701971\")) -> dt.19701971\n",
    "dt %>%\n",
    "  dplyr::filter(str_detect(id, \"19711972\")) -> dt.19711972\n",
    "dt %>%\n",
    "  dplyr::filter(str_detect(id, \"19721973\")) -> dt.19721973\n",
    "dt %>%\n",
    "  dplyr::filter(str_detect(id, \"19731974\")) -> dt.19731974\n",
    "dt %>%\n",
    "  dplyr::filter(str_detect(id, \"19741975\")) -> dt.19741975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "write(dt.19691970$sprkbrt, \"corpus19691970dt.txt\")\n",
    "write(dt.19701971$sprkbrt, \"corpus19701971dt.txt\")\n",
    "write(dt.19711972$sprkbrt, \"corpus19711972dt.txt\")\n",
    "write(dt.19721973$sprkbrt, \"corpus19721973dt.txt\")\n",
    "write(dt.19731974$sprkbrt, \"corpus19731974dt.txt\")\n",
    "write(dt.19741975$sprkbrt, \"corpus19741975dt.txt\")\n",
    "#etc for all other years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## data prepared! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train word2vec model --------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prepared txts in envir\n",
    "# create object with directory where files are in # this is workstation-specific!\n",
    "data.dir <- c(\"Q:/Onderzoeksdata_Milan/Surfdrive_milan/Shared/Dialects_of_Discord/Raw_data/Plain_texts_timeslot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all files with .txt file type. make sure only the txt files needed are in the directory!\n",
    "files <- readtext(paste0(data.dir, \"/1970-1975*\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train overall model 1970-1975 -------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set text as character\n",
    "all.7075 <- as.character(files$text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "# train word2vec\n",
    "model.all.7075 <- word2vec(x = all.7075, min_count = 5, threads = 4, type = 'skip-gram', dim = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create matrix\n",
    "emb.all.7075 <- as.matrix(model.all.7075)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train party specific models ---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object with directory where files are in # this is workstation-specific!\n",
    "data.dir2 <- c(\"Q:/Onderzoeksdata_Milan/Surfdrive_milan/Shared/Dialects_of_Discord/Raw_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# load all files with .txt file type. make sure only the txt files needed are in the directory!\n",
    "files2 <- readtext(paste0(data.dir2, \"/Plain_texts_party_spec_7075*\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPN\n",
    "# Subset specific year, set as character vector to serve as input for word2vec package\n",
    "files2 %>%\n",
    "  filter(str_detect(doc_id, \"cpn\")) -> cpn.7075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set as character\n",
    "cpn.7075 <- as.character(cpn.7075$text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "# train word2vec\n",
    "model.cpn.7075 <- word2vec(x = cpn.7075, min_count = 5, threads = 4, type = 'skip-gram', dim = 100, iter = 20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create matrix\n",
    "emb.cpn.7075 <- as.matrix(model.cpn.7075)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset specific year, set as character vector to serve as input for word2vec package\n",
    "files2 %>%\n",
    "  filter(str_detect(doc_id, \"vvd\")) -> vvd.7075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set as character\n",
    "vvd.7075 <- as.character(vvd.7075$text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "# train word2vec\n",
    "model.vvd.7075 <- word2vec(x = vvd.7075, min_count = 5, threads = 4, type = 'skip-gram', dim = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create matrix\n",
    "emb.vvd.7075 <- as.matrix(model.vvd.7075)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PvdA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset specific year, set as character vector to serve as input for word2vec package\n",
    "files2 %>%\n",
    "  filter(str_detect(doc_id, \"pvda\")) -> pvda.7075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set as character\n",
    "pvda.7075 <- as.character(pvda.7075$text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "# train word2vec\n",
    "model.pvda.7075 <- word2vec(x = pvda.7075, min_count = 5, threads = 4, type = 'skip-gram', dim = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create matrix\n",
    "emb.pvda.7075 <- as.matrix(model.pvda.7075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CDA\n",
    "# Subset specific year, set as character vector to serve as input for word2vec package\n",
    "files2 %>%\n",
    "  filter(str_detect(doc_id, \"cda\")) -> cda.7075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set as character\n",
    "cda.7075 <- as.character(cda.7075$text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "# train word2vec\n",
    "model.cda.7075 <- word2vec(x = cda.7075, min_count = 5, threads = 4, type = 'skip-gram', dim = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create matrix\n",
    "emb.cda.7075 <- as.matrix(model.cda.7075)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training complete, go to analysis in next script 2_analyse_plot_7075_parties.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".R",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
